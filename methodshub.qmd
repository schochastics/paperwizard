---
engine: knitr
format:
  html:
    embed-resources: true
  gfm: default
---

# paperwizard - Scrape News Sites using 'readability.js'
<!--
General specifications:
- This specification of the Methods Hub friendly README often uses the word 'should' to indicate the usual case. If you feel you need to do it differently, add a comment to argue for your case when you submit your method.
- A Methods Hub friendly README should contain all sections below that are not marked as optional, and can contain more sections.
- A Methods Hub friendly README should contain as few technical terms as possible and explain (or link to an explanation of) all used technical terms.
- A Methods Hub friendly README should link to all code files that it mentions using the [text](URL relative to this file) format. The relative URL (i.e., no "https://github.com") is neccessary for proper versioning in Methods Hub.
- A Methods Hub friendly README should contain an explanation (in the text) and an alternative for each image it contains (e.g., data models, pipeline, schema structure). Format: ![alternative text that describes what is visible in the image](URL relative to this file).
- A Methods Hub friendly README should link to authoritative sources rather than containing a copy of the information (e.g., documentation).
- A Methods Hub friendly README should use a uniform citation style for all references, for example APA7 https://apastyle.apa.org/style-grammar-guidelines/references/examples

Title:
1. The title must be the README's only first-level heading (line starting with a single '#').
2. The title should make the method's purpose clear.
3. The title (line 1 of this file) must be changed by you, but all other headings should be kept as they are.
4. The title must be appropriate (not harmful, derogatory, etc.).

Section templates:
The README template comes with text templates for each section (after each comment) that can be used, customized or removed as desired.
-->

## Description
<!--
1. Provide a brief and exact description of the method clearly mentioning its purpose i.e., what the method does or aims to achieve in abstract terms (avoiding technical details).
2. The focus should be on explaining the method in a way that helps users with different levels of expertise understand what it does, without going into technical details. It should clearly describe what inputs are needed and what outputs can be expected.
3. Briefly explain the input and output of the method and its note worthy features.
4. Provide link(s) to related papers from the social science domain using the method or similar methods for solving social science research questions. 
5. In a separate paragraph, highlight the reproducibility aspect of the method providing details or references to the resources used by the method, the data used in building the pre-trained modules etc.
6. It should also discuss the decisions and parameters controlling the behavior of the method.
-->

Uses Mozillas readability.js to scrape text from news websites without dedicated scrapers.

## Keywords

<!-- EDITME -->

* Digital Behavioral Data 
* news scraping
* data gathering

## Use Cases
<!--
1. The use cases section should contain a list of use cases relevant to the social sciences.
2. Each use case should start with a description of a task and then detail how one can use the method to assist in the task.
3. Each use case may list publications in which the use case occurs (e.g., in APA7 style, https://apastyle.apa.org/style-grammar-guidelines/references/examples).
-->

Extracting content from news websites is a powerful tool for social science research, enabling large-scale analysis of media narratives, framing, and information dissemination. By systematically gathering articles across outlets, researchers can study media bias, agenda-setting, and the representation of events or social groups. This data can uncover how different regions, political orientations, or journalistic styles shape public discourse and influence opinion. It also facilitates temporal studies of how news coverage evolves during crises, elections, or significant cultural moments. Using techniques like sentiment analysis, topic modeling, and network mapping of sources and citations, researchers can investigate the dynamics of information flow, echo chambers, and the global spread of narratives. Such insights are crucial for understanding the role of media in shaping societal values, attitudes, and behaviors in a rapidly changing digital landscape.

## Input Data
<!--
1. The input data section should illustrate the input data format by showing a (possibly abbreviated) example item and explaining (or linking to an explanation of) the data fields.
2. The input data section should specify which parts of the input data are optional and what effect it has to not provide these.
3. The input data section should link to a small example input file in the same repository that can be used to test the method (this test should be described in the section "How to Use").
-->

The package does not require imput data besides URLs of news articles.

## Output Data
<!--
1. The output data section should illustrate the output data format by showing a (possibly abbreviated) example item and explaining (or linking to an explanation of) the data fields.
2. The output data section should link to a small example output file in the same repository that can be re-created (as far as the method is non-random) from the input data (as described in the section "How to Use").
-->

After running `pw_deliver()`, **paperwizard** returns a clean and structured tibble that contains all essential information extracted from the target webpage. The output includes one row per successfully processed article and several standardized columns describing the article metadata and text content.

```{r}
url <- "https://theconversation.com/generative-ai-online-platforms-and-compensation-for-content-the-need-for-a-new-framework-242847"
article <- paperwizard::pw_deliver(url)
str(article)
```

```
tibble [1 × 9] (S3: tbl_df/tbl/data.frame)
 $ url         : chr "https://theconversation.com/generative-ai-online-platforms-and-compensation-for-content-the-need-for-a-new-framework-242847"
 $ expanded_url: chr "https://theconversation.com/generative-ai-online-platforms-and-compensation-for-content-the-need-for-a-new-framework-242847"
 $ domain      : chr "theconversation.com"
 $ status      : num 200
 $ datetime    : POSIXct[1:1], format: "2025-02-10 16:14:29"
 $ author      : chr "Thomas Paris"
 $ headline    : chr "Generative AI, online platforms and compensation for content: the need for a new framework"
 $ text        : chr "The emergence of generative artificial intelligence has put the issue of compensation for content producers bac" ...
 $ misc        :List of 1
```

### Field descriptions

| Field | Description |
|-------|--------------|
| `url` | The original URL supplied to `pw_deliver()`. |
| `expanded_url` | The resolved, fully expanded URL after redirects. |
| `domain` | The domain name of the website. |
| `status` | HTTP status code returned when fetching the page (e.g., 200 for success). |
| `datetime` | The publication date and time (if detected). |
| `author` | The article’s author. |
| `headline` | The extracted headline of the article. |
| `text` | The cleaned, readable article body as plain text. |
| `misc` | A nested list containing the raw output from the Readability.js parser (useful for debugging or accessing additional metadata such as excerpt, site name, or word count). |

A shortened example of the `misc` field:

```{r}
article$misc[[1]]
# $title         "Generative AI, online platforms and compensation for content..."
# $byline        "Thomas Paris"
# $siteName      "The Conversation"
# $excerpt       "How will content creators be compensated for material used by AI?"
# $publishedTime "2025-02-10T16:14:29Z"
```

## Hardware Requirements
<!--
1. The hardware requirements section should list all requirements (storage, memory, compute, GPUs, cluster software, ...) that exceed the capabilities of a cheap virtual machine provided by cloud computing company (2 x86 CPU core, 4 GB RAM, 40GB HDD).
2. If the method requires a GPU, the hardware requirements section must list the minimal GPU requirements (especially VRAM).
-->

Paperwizard runs on any hardware that can run R.

## Environment Setup
<!--
1. The environment setup section should list all requirements and provide all further steps to prepare an environment for running the method (installing requirements, downloading files, creating directoriees, etc.).
2. The environment setup section should recommend to use a virtual environment or similar if the programming language supports one.
-->

With R installed:

```r
install.packages("devtools")
devtools::install_github("schochastics/paperwizard")
```

## How to Use
<!--
1. The how to use section should provide the list of steps that are necessary to produce the example output file (see section Output Data) after having set up the environment (see section Environment Setup).
2. The how to use section should explain how to customize the steps to one's own needs, usually through configuration files or command line parameters, or refer to the appropriate open documentation.
-->

The package has one major function `pw_deliver()` which takes URLs as input and outputs a dataframe of article meta data and the text of the article.

## Technical Details
<!--
1. The technical details section should proview a process overview, linking to key source code files at every step of the process.
2. In case a publication provides the details mentioned below, the technical details section should link to this publication using a sentence like "See the [publication](url-of-publication-best-using-doi) for ...". In this case, the mentioned technical details can be omitted from the section.
3. The technical details section should list all information needed to reproduce the method, including employed other methods and selected parameters.
4. The input data section should link to external data it uses, preferably using a DOI to a dataset page or to API documentation.
5. The technical details section should mention how other methods and their parameters were selected and which alternatives were tried.
6. The technical details section should for employed machine learning models mention on what kind of data they were trained.
-->

Check the official [blog post](https://blog.schochastics.net/posts/2025-02-12_paperwizard-scrape-news-articles/) for further information about technical details.

<!--## References -->
<!--
1. The references section is optional, especially if they are cited in a publication that explains the technical details (see section Technical Details).
2. The references section should provide references of publications related to this method (e.g., in APA7 style, https://apastyle.apa.org/style-grammar-guidelines/references/examples).
-->

<!-- ## Acknowledgements -->
<!--
1. The acknowledgments section is optional.
2. The acknowledgments section should list expressions of gratitude to people or organizations who contributed, supported or guided.
-->

<!-- ## Disclaimer-->
<!--
1. The disclaimer section is optional.
2. The disclaimer section should list disclaimers, legal notices, or usage restrictions for the method.
-->

## Contact Details
<!-- 
1. The contact details section should specify whom to contact for questions or contributions and how (can be separate entitites; for example email addresses or links to the GitHub issue board).
-->

Maintainer: David Schoch <david@schochastics.net>

Issue Tracker: [https://github.com/schochastics/paperwizard/issues](https://github.com/schochastics/paperwizard/issues)
